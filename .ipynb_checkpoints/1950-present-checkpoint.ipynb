{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp laptop 15\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping population data for 234 countries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [05:06<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All country population data saved to world_population_1950_present.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar for tracking\n",
    "\n",
    "# Base URL for Worldometer world population\n",
    "base_url = \"https://www.worldometers.info/world-population/population-by-country/\"\n",
    "\n",
    "# Function to get all country URLs\n",
    "def get_country_links():\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch the country list page\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"id\": \"example2\"})  # Locate the country list table\n",
    "    country_links = table.find_all(\"a\")\n",
    "    \n",
    "    country_urls = {}\n",
    "    for link in country_links:\n",
    "        country_name = link.text.strip()\n",
    "        country_url = \"https://www.worldometers.info\" + link['href']\n",
    "        country_urls[country_name] = country_url\n",
    "\n",
    "    return country_urls\n",
    "\n",
    "# Function to scrape population data from a country page\n",
    "def scrape_population_data(country_name, country_url):\n",
    "    response = requests.get(country_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {country_name}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"class\": \"table table-striped table-bordered table-hover table-condensed table-list\"})\n",
    "    rows = table.find_all(\"tr\")[1:]  # Skip header row\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        year = cols[0].text.strip()\n",
    "        population = cols[1].text.strip()\n",
    "        yearly_change = cols[2].text.strip()\n",
    "        net_change = cols[3].text.strip()\n",
    "        density = cols[4].text.strip()\n",
    "        urban_pop = cols[5].text.strip()\n",
    "        urban_pop_pct = cols[6].text.strip()\n",
    "\n",
    "        data.append([country_name, year, population, yearly_change, net_change, density, urban_pop, urban_pop_pct])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Main script to scrape data for all countries\n",
    "all_countries = get_country_links()\n",
    "if not all_countries:\n",
    "    print(\"No countries found. Exiting.\")\n",
    "else:\n",
    "    all_data = []\n",
    "\n",
    "    print(f\"Scraping population data for {len(all_countries)} countries...\")\n",
    "\n",
    "    for country, url in tqdm(all_countries.items()):\n",
    "        country_data = scrape_population_data(country, url)\n",
    "        if country_data:\n",
    "            all_data.extend(country_data)\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        \"Country\", \"Year\", \"Population\", \"Yearly Change\", \"Net Change\", \"Density (P/Km²)\", \"Urban Population\", \"Urban Population %\"\n",
    "    ])\n",
    "\n",
    "    # Save data to CSV\n",
    "    df.to_csv(\"world_population_1950_present.csv\", index=False)\n",
    "\n",
    "    print(\"All country population data saved to world_population_1950_present.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
